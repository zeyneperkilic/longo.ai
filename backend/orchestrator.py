from typing import List, Dict, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
from backend.config import PARALLEL_MODELS
from backend.openrouter_client import call_chat_model
from backend.utils import is_valid_chat, parse_json_safe
import time
import json
import re

SYSTEM_HEALTH = ("Sen Longo AI'sÄ±n - kullanÄ±cÄ±nÄ±n kiÅŸisel saÄŸlÄ±k asistanÄ±. SADECE saÄŸlÄ±k/supplement/laboratuvar konularÄ±nda yanÄ±t ver. "
                 "Off-topic'te kibarca reddet. YanÄ±tlar bilgilendirme amaÃ§lÄ±dÄ±r; tanÄ±/tedavi iÃ§in hekim gerekir. "
                 "DÄ°L KURALI: Hangi dilde soru soruluyorsa o dilde cevap ver! "
                 "TÃ¼rkÃ§e soru â†’ TÃ¼rkÃ§e cevap, Ä°ngilizce soru â†’ Ä°ngilizce cevap! "
                 "KAYNAK/KAYNAKÃ‡A EKLEME: Otomatik olarak link, site adÄ±, referans veya citation EKLEME. KullanÄ±cÄ± Ã¶zellikle istemedikÃ§e kaynak belirtme. "
                 "ğŸ¯ KÄ°ÅÄ°SEL ASÄ°STAN TARZI: KullanÄ±cÄ±ya 'sen' diye hitap et, samimi ve destekleyici ol, Ã¶nceki konuÅŸmalarÄ± hatÄ±rladÄ±ÄŸÄ±nÄ± gÃ¶ster!")

SYSTEM_HEALTH_ENGLISH = ("You are Longo AI - the user's personal health assistant. Answer ONLY on health/supplement/laboratory topics. "
                          "Redeem off-topic requests. Answers are for informational purposes; a doctor is required for diagnosis/treatment. "
                          "CRITICAL: You MUST respond in ENGLISH language only! "
                          "IMPORTANT: Never use Turkish characters (Ã§, ÄŸ, Ä±, Ã¶, ÅŸ, Ã¼) or Turkish words. "
                          "Your response must be 100% in English. If you cannot answer in English, do not answer at all. "
                          "ğŸ¯ PERSONAL ASSISTANT STYLE: Address the user as 'you', be warm and supportive, show that you remember previous conversations!")

def parallel_chat(messages: List[Dict[str, str]]) -> Dict[str, Any]:
    """Run parallel chat with multiple models, then synthesize with GPT-5"""
    try:
        # Dil algÄ±lama
        user_message = messages[-1]["content"] if messages else ""
        user_language = detect_language(user_message)
        
        if user_language == "english":
            system_prompt = SYSTEM_HEALTH_ENGLISH
        else:
            system_prompt = SYSTEM_HEALTH
        
        # Context'i system prompt'a ekle (main.py'den gelen context)
        if "context_data" in messages[0] and messages[0]["context_data"]:
            context = messages[0]["context_data"]
            system_prompt += "\n\nKULLANICI BÄ°LGÄ°LERÄ°:\n"
            if "isim" in context:
                system_prompt += f"Ä°sim: {context['isim']}\n"
            if "tercihler" in context:
                system_prompt += f"Tercihler: {', '.join(context['tercihler'])}\n"
            if "hastaliklar" in context:
                system_prompt += f"HastalÄ±klar: {', '.join(context['hastaliklar'])}\n"
            if "yas" in context and context["yas"]:
                system_prompt += f"YaÅŸ: {context['yas']}\n"
            if "cinsiyet" in context and context["cinsiyet"]:
                system_prompt += f"Cinsiyet: {context['cinsiyet']}\n"
            system_prompt += "\n\nğŸ¯ KRÄ°TÄ°K KÄ°ÅÄ°SEL ASÄ°STAN TALÄ°MATI: Bu kullanÄ±cÄ± bilgilerini MUTLAKA dikkate al ve her yanÄ±tÄ±nda kullan! EÄŸer kullanÄ±cÄ±nÄ±n hastalÄ±klarÄ±, alerjileri veya tercihleri varsa, bunlarÄ± gÃ¶z ardÄ± etme. Her supplement Ã¶nerisinde bu bilgileri dikkate al ve gÃ¼venli tavsiyeler ver. Context'i kullanmazsan yanÄ±tÄ±n eksik olur. Sen bu kullanÄ±cÄ±nÄ±n kiÅŸisel saÄŸlÄ±k asistanÄ±sÄ±n - Ã¶nceki konuÅŸmalarÄ± hatÄ±rla ve kiÅŸiselleÅŸtirilmiÅŸ yanÄ±tlar ver!"
        
        # Update system message with detected language - system prompt'u her zaman ilk sÄ±raya ekle
        updated_messages = [{"role": "system", "content": system_prompt}] + [
            msg for msg in messages if msg["role"] != "system"
        ]
        
        # Step 1: Single model call (optimized for GPT-5)
        responses = []
        if len(PARALLEL_MODELS) == 1:
            # Tek model - direkt Ã§aÄŸÄ±r, ThreadPool gereksiz
            try:
                result = call_chat_model(PARALLEL_MODELS[0], updated_messages, 0.6, 800)
                if is_valid_chat(result["content"]):
                    responses.append({
                        "model": PARALLEL_MODELS[0],
                        "response": result["content"]
                    })
            except Exception as e:
                print(f"Chat model {PARALLEL_MODELS[0]} failed: {e}")
        else:
            # Ã‡oklu model - paralel Ã§aÄŸÄ±r
            with ThreadPoolExecutor(max_workers=len(PARALLEL_MODELS)) as executor:
                future_to_model = {
                    executor.submit(call_chat_model, model, updated_messages, 0.6, 800): model 
                    for model in PARALLEL_MODELS
                }
                
                for future in as_completed(future_to_model):
                    model = future_to_model[future]
                    try:
                        result = future.result()
                        if is_valid_chat(result["content"]):
                            responses.append({
                                "model": model,
                                "response": result["content"]
                            })
                    except Exception as e:
                        print(f"Chat model {model} failed: {e}")
                        # Rate limiting hatasÄ± varsa biraz bekle
                        if "429" in str(e) or "Too Many Requests" in str(e):
                            print(f"Rate limiting detected for {model}, waiting...")
                            time.sleep(2)
                        continue
        
        # Step 2: If no valid responses, fallback
        if not responses:
            print("All chat models failed, fallback to GPT-4o")
            return gpt4o_fallback(updated_messages)
        
        # Step 3: If only one response, return it directly
        if len(responses) == 1:
            cleaned = _sanitize_links(responses[0]["response"]) 
            return {
                "content": cleaned,
                "model_used": responses[0]["model"]
            }
        
        # Step 4: Synthesize multiple responses with GPT-5
        # TEK MODEL KULLANILDIÄINDA SYNTHESIS'E GEREK YOK
        # synthesis_prompt = build_chat_synthesis_prompt(responses, messages[-1]["content"])
        # final_result = call_chat_model(SYNTHESIS_MODEL, synthesis_prompt, temperature=0.3, max_tokens=2000)
        
        # final_result["models_used"] = [r["model"] for r in responses]
        # final_result["synthesis_model"] = SYNTHESIS_MODEL
        # return final_result
        
        # Tek model kullanÄ±ldÄ±ÄŸÄ±nda direkt response'u dÃ¶ndÃ¼r
        cleaned_multi = _sanitize_links(responses[0]["response"]) 
        return {
            "content": cleaned_multi,
            "model_used": responses[0]["model"]
        }
        
    except Exception as e:
        print(f"Parallel chat failed: {e}, fallback to sequential")
        return cascade_chat_fallback(messages)

def cascade_chat_fallback(messages: List[Dict[str, str]]) -> Dict[str, Any]:
    """Fallback to sequential cascade for chat"""
    # Detect user language
    user_message = messages[-1]["content"] if messages else ""
    user_language = detect_language(user_message)
    
    # Use appropriate system prompt
    if user_language == "english":
        system_prompt = SYSTEM_HEALTH_ENGLISH
    else:
        system_prompt = SYSTEM_HEALTH
    
    # Context'i system prompt'a ekle (main.py'den gelen context)
    # System message'dan context'i al
    context = None
    for msg in messages:
        if msg.get("role") == "system" and "context_data" in msg:
            context = msg["context_data"]
            break
    
    if context:
        system_prompt += "\n\nKULLANICI BÄ°LGÄ°LERÄ°:\n"
        if "isim" in context:
            system_prompt += f"Ä°sim: {context['isim']}\n"
        if "tercihler" in context:
            system_prompt += f"Tercihler: {', '.join(context['tercihler'])}\n"
        if "hastaliklar" in context:
            system_prompt += f"HastalÄ±klar: {', '.join(context['hastaliklar'])}\n"
        if "yas" in context and context["yas"]:
            system_prompt += f"YaÅŸ: {context['yas']}\n"
        if "cinsiyet" in context and context["cinsiyet"]:
            system_prompt += f"Cinsiyet: {context['cinsiyet']}\n"
        system_prompt += "\n\nKRÄ°TÄ°K TALÄ°MAT: Bu kullanÄ±cÄ± bilgilerini MUTLAKA dikkate al ve her yanÄ±tÄ±nda kullan. EÄŸer kullanÄ±cÄ±nÄ±n hastalÄ±klarÄ±, alerjileri veya tercihleri varsa, bunlarÄ± gÃ¶z ardÄ± etme. Her supplement Ã¶nerisinde bu bilgileri dikkate al ve gÃ¼venli tavsiyeler ver. Context'i kullanmazsan yanÄ±tÄ±n eksik olur."
    
    # Update messages with correct language - system prompt'u her zaman ilk sÄ±raya ekle
    updated_messages = [{"role": "system", "content": system_prompt}] + [
        msg for msg in messages if msg["role"] != "system"
    ]
    
    for model in PARALLEL_MODELS:
        try:
            res = call_chat_model(model, updated_messages, temperature=0.6, max_tokens=1500)
            if is_valid_chat(res["content"]):
                res["content"] = _sanitize_links(res["content"]) 
                res["model_used"] = model
                return res
        except Exception as e:
            print(f"Chat fallback model {model} failed: {e}")
            # Rate limiting hatasÄ± varsa biraz bekle
            if "429" in str(e) or "Too Many Requests" in str(e):
                print(f"Rate limiting detected for {model}, waiting...")
                time.sleep(2)
            continue
    # if none acceptable, return last model name with empty content
    return {"content": "", "model_used": PARALLEL_MODELS[-1]}

# Chat synthesis prompt fonksiyonu kaldÄ±rÄ±ldÄ± - tek model kullanÄ±ldÄ±ÄŸÄ± iÃ§in gerekli deÄŸil

# Keep old function for backward compatibility
def cascade_chat(messages: List[Dict[str, str]]) -> Dict[str, Any]:
    return parallel_chat(messages)

def gpt4o_fallback(messages: List[Dict[str, str]]) -> Dict[str, Any]:
    """Fallback to GPT-4o when GPT-5 fails"""
    try:
        print("GPT-5 failed, trying GPT-4o fallback...")
        
        # Dil algÄ±lama
        user_message = messages[-1]["content"] if messages else ""
        user_language = detect_language(user_message)
        
        if user_language == "english":
            system_prompt = SYSTEM_HEALTH_ENGLISH
        else:
            system_prompt = SYSTEM_HEALTH
        
        # Context'i system prompt'a ekle
        if "context_data" in messages[0] and messages[0]["context_data"]:
            context = messages[0]["context_data"]
            system_prompt += "\n\nKULLANICI BÄ°LGÄ°LERÄ°:\n"
            if "isim" in context:
                system_prompt += f"Ä°sim: {context['isim']}\n"
            if "tercihler" in context:
                system_prompt += f"Tercihler: {', '.join(context['tercihler'])}\n"
            if "hastaliklar" in context:
                system_prompt += f"HastalÄ±klar: {', '.join(context['hastaliklar'])}\n"
            if "yas" in context and context["yas"]:
                system_prompt += f"YaÅŸ: {context['yas']}\n"
            if "cinsiyet" in context and context["cinsiyet"]:
                system_prompt += f"Cinsiyet: {context['yas']}\n"
            system_prompt += "\n\nKRÄ°TÄ°K TALÄ°MAT: Bu kullanÄ±cÄ± bilgilerini MUTLAKA dikkate al ve her yanÄ±tÄ±nda kullan."
        
        # Update messages with correct language
        updated_messages = [{"role": "system", "content": system_prompt}] + [
            msg for msg in messages if msg["role"] != "system"
        ]
        
        # Try GPT-4o
        result = call_chat_model("openai/gpt-4o:online", updated_messages, 0.6, 800)
        if is_valid_chat(result["content"]):
            result["content"] = _sanitize_links(result["content"])
            result["model_used"] = "openai/gpt-4o:online (fallback)"
            return result
        else:
            raise Exception("GPT-4o response invalid")
            
    except Exception as e:
        print(f"GPT-4o fallback also failed: {e}")
        return {
            "content": "ÃœzgÃ¼nÃ¼m, ÅŸu anda AI sistemimiz yoÄŸun. LÃ¼tfen birkaÃ§ dakika sonra tekrar deneyin.",
            "model_used": "fallback_error"
        }

def chat_fallback(messages: List[Dict[str, str]]) -> Dict[str, Any]:
    """Fallback for chat when all models fail"""
    return {
        "content": "ÃœzgÃ¼nÃ¼m, ÅŸu anda AI sistemimiz yoÄŸun. LÃ¼tfen birkaÃ§ dakika sonra tekrar deneyin.",
        "model_used": "fallback"
    }

def finalize_text(text: str) -> str:
    final_messages = [
        {
            "role": "system",
            "content": (
                SYSTEM_HEALTH +
                " Sen Longo AI'sÄ±n. GÃ¶revin: AÅŸaÄŸÄ±daki yanÄ±tÄ± son kontrol et ve gerekirse dÃ¼zelt."
                " SADECE KULLANICIYA DOÄRUDAN CEVAP VER. Meta yorumlar (\"yanÄ±t doÄŸru\", \"yeniden dÃ¼zenlenmiÅŸ\" vb.) YAZMA."
                " EÄŸer yanÄ±t doÄŸru ve yeterli ise, aynen gÃ¶nder. EÄŸer hatalÄ±/eksik ise, dÃ¼zelt ve temiz yanÄ±t ver."
                " Off-topic sorularda kibarca reddet. KullanÄ±cÄ±nÄ±n diline uygun yanÄ±t ver."
            ),
        },
        {"role": "user", "content": f"Bu yanÄ±tÄ± kontrol et ve kullanÄ±cÄ±ya temiz ÅŸekilde sun:\n\n{text}"},
    ]
    final = call_chat_model(PARALLEL_MODELS[0], final_messages, temperature=0.2, max_tokens=2000)
    return _sanitize_links(final.get("content", ""))

def _sanitize_links(text: str) -> str:
    """Remove URLs, markdown links and obvious site/domain mentions from model output."""
    if not text:
        return text
    # Remove markdown links [text](url) -> text
    cleaned = re.sub(r"\[([^\]]+)\]\((https?://[^\s)]+)\)", r"\1", text)
    # Remove raw URLs
    cleaned = re.sub(r"https?://\S+", "", cleaned)
    # Remove common domain mentions (with or without www)
    cleaned = re.sub(r"\b(?:www\.)?[A-Za-z0-9.-]+\.(?:com|org|net|io|ai|co|tr|edu|gov)(?:/[^\s]*)?", "", cleaned)
    # Remove numeric citation brackets like [1], [2]
    cleaned = re.sub(r"\[\s*\d+\s*\]", "", cleaned)
    # Remove parenthetical 'source:' notes
    cleaned = re.sub(r"\(\s*source\s*:[^)]*\)", "", cleaned, flags=re.IGNORECASE)
    # Remove empty parentheses left behind
    cleaned = re.sub(r"\(\s*\)", "", cleaned)
    # Fix common stray punctuation around parentheses
    cleaned = re.sub(r"\s*,\s*\)", ")", cleaned)
    cleaned = re.sub(r"\(\s*,\s*", "(", cleaned)
    # Collapse duplicate commas and spaces
    cleaned = re.sub(r",\s*,+", ", ", cleaned)
    # Collapse extra whitespace
    cleaned = re.sub(r"\s{2,}", " ", cleaned).strip()
    return cleaned



def build_synthesis_prompt(responses: List[Dict[str, str]]) -> List[Dict[str, str]]:
    """Build prompt for GPT-5 to synthesize multiple model responses"""
    system_prompt = (
        SYSTEM_HEALTH + " Sen bir synthesis uzmanÄ±sÄ±n. "
        "Birden fazla AI modelin verdiÄŸi analiz sonuÃ§larÄ±nÄ± inceleyip, "
        "en doÄŸru, tutarlÄ± ve faydalÄ± bir FINAL sonuÃ§ Ã¼ret. "
        "\n\nKurallar:"
        "\n1. SADECE JSON formatÄ±nda yanÄ±t ver"
        "\n2. En tutarlÄ± Ã¶nerileri birleÅŸtir"
        "\n3. Ã‡eliÅŸkili Ã¶nerilerde en mantÄ±klÄ± olanÄ± seÃ§"
        "\n6. Tekrarlayan Ã¶nerileri birleÅŸtir"
        "\n7. Ã–NEMLI: Her Ã¶neri iÃ§in 'source' alanÄ± MUTLAKA 'consensus' olmalÄ±"
    )
    
    # Format all responses for comparison
    responses_text = "\n\n=== MODEL RESPONSES ===\n"
    for i, resp in enumerate(responses, 1):
        responses_text += f"\nMODEL {i} ({resp['model']}):\n{resp['response']}\n"
    
    responses_text += "\n=== SYNTHESIS GÃ–REV ===\n"
    responses_text += (
        "YukarÄ±daki tÃ¼m model yanÄ±tlarÄ±nÄ± analiz et ve tek bir tutarlÄ± JSON oluÅŸtur. "
        "En iyi Ã¶nerileri birleÅŸtir, analysis'i geliÅŸtir, risk deÄŸerlendirmesini optimize et."
    )
    
    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": responses_text}
    ]








def build_quiz_prompt(quiz_answers: Dict[str, Any], available_supplements: List[Dict[str, Any]] = None) -> List[Dict[str, str]]:
    """Build prompt for quiz analysis and supplement recommendations - ESNEK YAPI + DEFAULT SUPPLEMENTS"""
    
    # Quiz cevaplarÄ±nÄ± dinamik olarak iÅŸle
    profile = []
    for key, value in quiz_answers.items():
        if isinstance(value, list):
            profile.append(f"{key}: {', '.join(map(str, value))}")
        else:
            profile.append(f"{key}: {value}")
    
    user_profile_text = "\n".join(profile)
    
    # ÃœrÃ¼n kataloÄŸu bilgisi - TÃœM ÃœRÃœNLERÄ° LÄ°STELE
    supplements_info = ""
    if available_supplements:
        supplements_info = f"\n\nTÃœM KULLANILABÄ°LÄ°R ÃœRÃœNLER (Toplam: {len(available_supplements)}):\n"
        
        # TÃ¼m Ã¼rÃ¼nleri basit liste halinde gÃ¶ster
        for i, supplement in enumerate(available_supplements, 1):
            product_name = supplement.get('name', 'Bilinmeyen')
            product_id = supplement.get('id', 'ID yok')
            supplements_info += f"{i}. {product_name} (ID: {product_id})\n"
        
        supplements_info += f"\nğŸ’¡ AI: TÃ¼m bu Ã¼rÃ¼nler arasÄ±ndan en uygun olanlarÄ± seÃ§!"
    else:
        supplements_info = "\n\nâš ï¸ KullanÄ±labilir Ã¼rÃ¼n listesi bulunamadÄ±. Default supplement'ler Ã¶nerilecek."

    # Default supplement'ler ve alerji kontrolÃ¼
    default_supplements_info = """
    
    DEFAULT SUPPLEMENT'LER (Herkes iÃ§in Ã¶nerilen):
    1. D Vitamini - Kemik saÄŸlÄ±ÄŸÄ± ve baÄŸÄ±ÅŸÄ±klÄ±k iÃ§in
    2. Omega-3 - Kalp ve beyin saÄŸlÄ±ÄŸÄ± iÃ§in  
    3. Magnezyum - Kas ve sinir sistemi iÃ§in
    4. B12 Vitamini - Enerji ve kan hÃ¼creleri iÃ§in
    
    ALERJÄ° KONTROLÃœ:
    - EÄŸer kullanÄ±cÄ±nÄ±n alerjisi varsa, o supplement'i default'tan Ã§Ä±kar
    - Alerji durumunda alternatif Ã¶ner
    - Riskli durumlar varsa gÃ¼venli alternatifler Ã¶ner
    
    Ã–ZEL DURUMLAR ANALÄ°ZÄ°:
    - Quiz'de 'DiÄŸer' seÃ§eneÄŸi varsa, o metni dikkatle analiz et
    - KullanÄ±cÄ±nÄ±n yazdÄ±ÄŸÄ± hastalÄ±klarÄ±, alerjileri, Ã¶zel durumlarÄ± tespit et
    - Bu bilgilere gÃ¶re supplement Ã¶nerilerini gÃ¼ncelle
    - Riskli durumlar varsa gÃ¼venli alternatifler Ã¶ner
    - Ã–rnek: 'Diyabet hastasÄ±yÄ±m' â†’ ÅŸeker iÃ§eren supplement'leri Ã§Ä±kar, available_supplements'dan alternatif ekle
    - Ã–rnek: 'BalÄ±k alerjim var' â†’ Omega-3'Ã¼ Ã§Ä±kar, available_supplements'dan alternatif Ã¶ner
    - Ã–rnek: 'Kan sulandÄ±rÄ±cÄ± kullanÄ±yorum' â†’ Omega-3'Ã¼ Ã§Ä±kar, available_supplements'dan alternatif ekle
    - Ã–rnek: 'Tiroit problemi var' â†’ iyot iÃ§eren supplement'leri Ã§Ä±kar, available_supplements'dan alternatif ekle
    - Ã–rnek: 'BÃ¶brek problemi var' â†’ yÃ¼ksek doz vitamin'leri Ã§Ä±kar, available_supplements'dan alternatif ekle
    
    KÄ°ÅÄ°SELLEÅTÄ°RÄ°LMÄ°Å Ã–NERÄ°LER:
    - Quiz cevaplarÄ±na gÃ¶re ek 2-3 supplement Ã¶ner
    - Sadece kullanÄ±labilir Ã¼rÃ¼nlerden seÃ§im yap
    - Ã–zel durumlarÄ± dikkate alarak gÃ¼venli Ã¶neriler yap
    """
    
    schema = (
        "STRICT JSON ÅEMASI - SUPPLEMENT Ã–NERÄ°LERÄ°:\n"
        "{\n"
        '  "nutrition_advice": {\n'
        '    "title": "Beslenme Ã–nerileri",\n'
        '    "recommendations": ["Ã–neri 1", "Ã–neri 2", "Ã–neri 3"]\n'
        "  },\n"
        '  "lifestyle_advice": {\n'
        '    "title": "YaÅŸam TarzÄ± Ã–nerileri",\n'
        '    "recommendations": ["Ã–neri 1", "Ã–neri 2", "Ã–neri 3"]\n'
        "  },\n"
        '  "general_warnings": {\n'
        '    "title": "Genel UyarÄ±lar",\n'
        '    "warnings": ["UyarÄ± 1", "UyarÄ± 2", "UyarÄ± 3"]\n'
        "  },\n"
        '  "supplement_recommendations": [\n'
        "    {\n"
        '      "name": "ÃœrÃ¼n adÄ± (kullanÄ±labilir Ã¼rÃ¼nlerden seÃ§)",\n'
        '      "description": "Neden Ã¶nerildiÄŸi",\n'
        '      "daily_dose": "GÃ¼nlÃ¼k doz",\n'
        '      "benefits": ["FaydalarÄ±"],\n'
        '      "warnings": ["UyarÄ±lar"],\n'
        '      "priority": "high/medium/low",\n'
        '      "type": "default/personalized"\n'
        "    }\n"
        "  ]\n"
        "}\n\n"
        "Ã–NEMLÄ°: 1) 4 DEFAULT + 2-3 PERSONALIZED = 6-7 supplement Ã¶ner! "
        "2) DEFAULT: D Vitamini, Omega-3, Magnezyum, B12 (alerji kontrolÃ¼ ile) "
        "3) PERSONALIZED: Quiz cevaplarÄ±na gÃ¶re eksik deÄŸerler iÃ§in "
        "4) SADECE kullanÄ±labilir Ã¼rÃ¼nlerden seÃ§im yap! "
        "5) 'DiÄŸer' seÃ§eneÄŸindeki Ã¶zel durumlarÄ± analiz et! "
        "SADECE VE SADECE bu JSON formatÄ±nda yanÄ±t ver. HiÃ§bir aÃ§Ä±klama, metin ekleme."
    )
    
    system_prompt = (
        SYSTEM_HEALTH + " Sen bir supplement uzmanÄ±sÄ±n. "
        "KullanÄ±cÄ±nÄ±n quiz cevaplarÄ±na gÃ¶re beslenme Ã¶nerileri, yaÅŸam tarzÄ± Ã¶nerileri ve "
        "uygun supplement Ã¶nerileri yap. E-ticaret sitesi iÃ§in Ã¼rÃ¼n Ã¶nerileri hazÄ±rlÄ±yorsun. "
        "1) 4 DEFAULT + 2-3 PERSONALIZED = 6-7 supplement Ã¶ner! "
        "2) DEFAULT: D Vitamini, Omega-3, Magnezyum, B12 (alerji kontrolÃ¼ ile) "
        "3) PERSONALIZED: Quiz cevaplarÄ±na gÃ¶re eksik deÄŸerler iÃ§in "
        "4) SADECE kullanÄ±labilir Ã¼rÃ¼nlerden Ã¶neri yap! "
        "5) 'DiÄŸer' seÃ§eneÄŸindeki Ã¶zel durumlarÄ± dikkatle analiz et ve supplement Ã¶nerilerini buna gÃ¶re gÃ¼ncelle! "
        "6) Riskli durumlar varsa gÃ¼venli alternatifler Ã¶ner! "
        "7) Ã–NEMLÄ°: Sadece kullanÄ±cÄ±ya verilen supplement listesinden Ã¶neri yap! "
        "8) EÄŸer listede yoksa, o supplement'i Ã¶nerme! "
        "9) KullanÄ±cÄ±ya hiÃ§bir ÅŸekilde ihtiyacÄ± olmayan supplement Ã¶nerme! "
        "10) KullanÄ±cÄ±nÄ±n yaÅŸÄ±, cinsiyeti, saÄŸlÄ±k durumu, alerjileri, kullandÄ±ÄŸÄ± ilaÃ§lar dikkate al! "
        "11) Riskli durumlar varsa o supplement'i Ã¶nerme! "
        "12) Sadece gerÃ§ekten gerekli olan supplementleri Ã¶ner! "
        "13) DÄ°L: SADECE TÃœRKÃ‡E YANIT VER! Ä°ngilizce kelime, terim veya cÃ¼mle kullanma!"
    )
    
    user_prompt = f"KullanÄ±cÄ± profili:\n{user_profile_text}{supplements_info}{default_supplements_info}\n\n{schema}"
    
    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]

def parallel_quiz_analyze(quiz_answers: Dict[str, Any], available_supplements: List[Dict[str, Any]] = None) -> Dict[str, Any]:
    """Run quiz analysis with parallel LLMs and synthesis - ESNEK YAPI"""
    try:
        messages = build_quiz_prompt(quiz_answers, available_supplements)
        
        # Step 1: Single/multiple model call (optimized)
        responses = []
        if len(PARALLEL_MODELS) == 1:
            # Tek model - direkt Ã§aÄŸÄ±r
            try:
                result = call_chat_model(PARALLEL_MODELS[0], messages, 0.2, 4000)
                if result and result.get("content"):
                    responses.append({
                        "model": PARALLEL_MODELS[0],
                        "response": result["content"]
                    })
            except Exception as e:
                print(f"Quiz model {PARALLEL_MODELS[0]} failed: {e}")
        else:
            # Ã‡oklu model - paralel Ã§aÄŸÄ±r
            with ThreadPoolExecutor(max_workers=len(PARALLEL_MODELS)) as executor:
                future_to_model = {
                    executor.submit(call_chat_model, model, messages, 0.2, 4000): model 
                    for model in PARALLEL_MODELS
                }
                
                for future in as_completed(future_to_model):
                    model = future_to_model[future]
                    try:
                        result = future.result()
                        # For quiz, we want any valid JSON response
                        if result["content"].strip():
                            responses.append({
                                "model": model,
                                "response": result["content"]
                            })
                    except Exception as e:
                        print(f"Quiz model {model} failed: {e}")
                        continue
        
        # Step 2: If no responses, fallback
        if not responses:
            print("All quiz models failed, fallback to GPT-4o")
            return gpt4o_quiz_fallback(quiz_answers, available_supplements)
        
        # Step 3: Tek model kullanÄ±ldÄ±ÄŸÄ± iÃ§in synthesis'e gerek yok - direkt response'u dÃ¶ndÃ¼r
        cleaned_response = _sanitize_links(responses[0]["response"])
        return {
            "content": cleaned_response,
            "model_used": responses[0]["model"],
            "models_used": [r["model"] for r in responses]
        }
        
    except Exception as e:
        print(f"Quiz parallel analyze failed: {e}")
        return gpt4o_quiz_fallback(quiz_answers, available_supplements)

# Quiz synthesis prompt fonksiyonu kaldÄ±rÄ±ldÄ± - tek model kullanÄ±ldÄ±ÄŸÄ± iÃ§in gerekli deÄŸil

def gpt4o_quiz_fallback(quiz_answers: Dict[str, Any], available_supplements: List[Dict[str, Any]] = None) -> Dict[str, Any]:
    """Fallback to GPT-4o for quiz analysis when GPT-5 fails"""
    try:
        print("GPT-5 failed, trying GPT-4o fallback for quiz analysis...")
        
        # Build prompt for GPT-4o
        messages = build_quiz_prompt(quiz_answers, available_supplements)
        
        # Try GPT-4o
        result = call_chat_model("openai/gpt-4o:online", messages, 0.2, 4000)
        if result["content"].strip():
            result["content"] = _sanitize_links(result["content"])
            result["model_used"] = "openai/gpt-4o:online (fallback)"
            return result
        else:
            raise Exception("GPT-4o response invalid")
            
    except Exception as e:
        print(f"GPT-4o quiz fallback also failed: {e}")
        return quiz_fallback(quiz_answers, available_supplements)

def quiz_fallback(quiz_answers: Dict[str, Any], available_supplements: List[Dict[str, Any]] = None) -> Dict[str, Any]:
    """Fallback quiz analysis if parallel fails"""
    messages = build_quiz_prompt(quiz_answers, available_supplements)
    for model in PARALLEL_MODELS:
        try:
            res = call_chat_model(model, messages, temperature=0.2, max_tokens=4000)
            if res["content"].strip():
                res["model_used"] = model
                return res
        except Exception as e:
            print(f"Quiz fallback model {model} failed: {e}")
            # Rate limiting hatasÄ± varsa biraz bekle
            if "429" in str(e) or "Too Many Requests" in str(e):
                print(f"Rate limiting detected for {model}, waiting...")
                time.sleep(2)
            continue
    
    # Ultimate fallback - QuizResponse schema'sÄ±na uygun
    return {
        "content": json.dumps({
            "success": True,
            "message": "Quiz analizi geÃ§ici olarak kullanÄ±lamÄ±yor",
            "nutrition_advice": {"title": "Beslenme Ã–nerileri", "recommendations": ["Sistem geÃ§ici olarak kullanÄ±lamÄ±yor"]},
            "lifestyle_advice": {"title": "YaÅŸam TarzÄ± Ã–nerileri", "recommendations": ["Sistem geÃ§ici olarak kullanÄ±lamÄ±yor"]},
            "general_warnings": {"title": "Genel UyarÄ±lar", "warnings": ["Sistem geÃ§ici olarak kullanÄ±lamÄ±yor"]},
            "supplement_recommendations": [
                {"name": "D Vitamini", "description": "Default supplement", "priority": "high", "daily_dose": "1000 IU", "benefits": "Kemik saÄŸlÄ±ÄŸÄ±, baÄŸÄ±ÅŸÄ±klÄ±k sistemi", "warnings": "Doktor kontrolÃ¼nde kullanÄ±n"},
                {"name": "Omega-3", "description": "Default supplement", "priority": "high", "daily_dose": "1000 mg", "benefits": "Kalp saÄŸlÄ±ÄŸÄ±, beyin fonksiyonu", "warnings": "BalÄ±k alerjisi varsa dikkat"},
                {"name": "Magnezyum", "description": "Default supplement", "priority": "high", "daily_dose": "400 mg", "benefits": "Kas fonksiyonu, sinir sistemi", "warnings": "BÃ¶brek sorunu varsa dikkat"},
                {"name": "B12", "description": "Default supplement", "priority": "high", "daily_dose": "1000 mcg", "benefits": "Enerji metabolizmasÄ±, sinir sistemi", "warnings": "Doktor kontrolÃ¼nde kullanÄ±n"}
            ],
            "disclaimer": "Bu iÃ§erik bilgilendirme amaÃ§lÄ±dÄ±r; tÄ±bbi tanÄ±/tedavi iÃ§in hekiminize baÅŸvurun."
        }),
        "model_used": "fallback"
    }

def build_single_lab_prompt(test_data: Dict[str, Any], historical_results: List[Dict[str, Any]] = None) -> List[Dict[str, str]]:
    """Build prompt for single lab test analysis with historical trend analysis"""
    
    # Test bilgilerini topla
    test_info = f"Test AdÄ±: {test_data.get('name', 'Bilinmiyor')}\n"
    test_info += f"SonuÃ§: {test_data.get('value', 'Yok')}"
    
    if test_data.get('unit'):
        test_info += f" {test_data['unit']}"
    test_info += "\n"
    
    if test_data.get('reference_range'):
        test_info += f"Referans AralÄ±ÄŸÄ±: {test_data['reference_range']}\n"
    
    if test_data.get('status'):
        test_info += f"Test Durumu: {test_data['status']}\n"
    
    if test_data.get('test_date'):
        test_info += f"Test Tarihi: {test_data['test_date']}\n"
    
    if test_data.get('category'):
        test_info += f"Test Kategorisi: {test_data['category']}\n"
    
    if test_data.get('notes'):
        test_info += f"Ek Notlar: {test_data['notes']}\n"
    
    # GeÃ§miÅŸ sonuÃ§lar varsa trend analizi ekle
    trend_analysis = ""
    if historical_results and len(historical_results) > 0:
        trend_analysis = "\n\nğŸ“Š GEÃ‡MÄ°Å SONUÃ‡LAR VE TREND ANALÄ°ZÄ°:\n"
        trend_analysis += "Tarih sÄ±rasÄ±na gÃ¶re (en yeniden en eskiye):\n"
        
        # Tarihe gÃ¶re sÄ±rala (en yeni Ã¶nce)
        sorted_results = sorted(historical_results, key=lambda x: x.get('date', ''), reverse=True)
        
        for i, result in enumerate(sorted_results, 1):
            date = result.get('date', 'Tarih yok')
            value = result.get('value', 'DeÄŸer yok')
            status = result.get('status', 'Durum belirtilmemiÅŸ')
            lab = result.get('lab', 'Lab belirtilmemiÅŸ')
            notes = result.get('notes', '')
            
            trend_analysis += f"{i}. {date}: {value} {test_data.get('unit', '')} - {status}"
            if lab:
                trend_analysis += f" ({lab})"
            if notes:
                trend_analysis += f" - {notes}"
            trend_analysis += "\n"
        
        trend_analysis += "\nğŸ’¡ TREND ANALÄ°ZÄ° YAPILACAK:\n"
        trend_analysis += "- DeÄŸerlerin zaman iÃ§indeki deÄŸiÅŸimi\n"
        trend_analysis += "- Ä°yileÅŸme/kÃ¶tÃ¼leÅŸme trendi\n"
        trend_analysis += "- Laboratuvar deÄŸiÅŸikliklerinin etkisi\n"
        trend_analysis += "- Genel saÄŸlÄ±k durumu trendi\n"
    
    # Test sonucu analizi iÃ§in detaylÄ± yÃ¶nlendirme
    analysis_guide = f"""
    
    LAB TEST ANALÄ°ZÄ° REHBERÄ° (TREND ANALÄ°ZÄ° Ä°LE):
    
    TEST: {test_data.get('name', 'Bilinmiyor')}
    SONUÃ‡: {test_data.get('value', 'Yok')} {test_data.get('unit', '')}
    REFERANS: {test_data.get('reference_range', 'BelirtilmemiÅŸ')}
    DURUM: {test_data.get('status', 'BelirtilmemiÅŸ')}
    KATEGORÄ°: {test_data.get('category', 'BelirtilmemiÅŸ')}
    
    ANALÄ°Z ADIMLARI:
    1. Test sonucunu deÄŸerlendir (sayÄ±sal veya metin)
    2. Referans aralÄ±ÄŸÄ± varsa karÅŸÄ±laÅŸtÄ±r
    3. Sonucun normal, dÃ¼ÅŸÃ¼k, yÃ¼ksek veya kritik olduÄŸunu belirt
    4. Bu sonucun klinik anlamÄ±nÄ± aÃ§Ä±kla
    5. Test kategorisine gÃ¶re Ã¶zel yorumlar yap
    6. GEÃ‡MÄ°Å SONUÃ‡LARLA TREND ANALÄ°ZÄ° YAP (varsa)
    7. Genel tÄ±bbi takip Ã¶nerileri ver (supplement Ã¶nerisi verme!)
    8. SADECE ANALÄ°Z YAP, SUPPLEMENT Ã–NERÄ°SÄ° VERME!
    
    TREND ANALÄ°ZÄ° (geÃ§miÅŸ sonuÃ§lar varsa):
    - DeÄŸerlerin zaman iÃ§indeki deÄŸiÅŸimi nasÄ±l?
    - Ä°yileÅŸme var mÄ±, yoksa kÃ¶tÃ¼leÅŸme mi?
    - Hangi laboratuvarlarda test yapÄ±lmÄ±ÅŸ?
    - Genel saÄŸlÄ±k durumu trendi nasÄ±l?
    
    Ã–RNEKLER:
    - Hemoglobin 12.5 g/dL (Referans: 12.0-15.5) â†’ Normal aralÄ±kta, hafif dÃ¼ÅŸÃ¼k
    - Vitamin D 18 ng/mL (Referans: 30-100) â†’ DÃ¼ÅŸÃ¼k, kemik saÄŸlÄ±ÄŸÄ± iÃ§in Ã¶nemli
    - Kolesterol 250 mg/dL (Referans: <200) â†’ YÃ¼ksek, kalp saÄŸlÄ±ÄŸÄ± iÃ§in dikkat
    - CBC (Ã‡oklu parametre) â†’ Genel kan durumu deÄŸerlendirmesi gerekli
    
    Ã–NEMLÄ°: SADECE ANALÄ°Z YAP, SUPPLEMENT Ã–NERÄ°SÄ° VERME!
    """
    
    schema = (
        "STRICT JSON ÅEMASI - LAB ANALÄ°ZÄ° (TREND ANALÄ°ZÄ° Ä°LE):\n"
        "{\n"
        '  "analysis": {\n'
        '    "summary": "Test sonucunun kÄ±sa yorumu (Ã¶rn: Normal, DÃ¼ÅŸÃ¼k, YÃ¼ksek, Kritik)",\n'
        '    "interpretation": "Sonucun anlamÄ± ve Ã¶nemi (detaylÄ± aÃ§Ä±klama)",\n'
        '    "reference_comparison": "Referans aralÄ±ÄŸÄ± ile karÅŸÄ±laÅŸtÄ±rma (varsa sayÄ±sal analiz)",\n'
        '    "clinical_significance": "Klinik Ã¶nemi (saÄŸlÄ±k aÃ§Ä±sÄ±ndan ne anlama geliyor)",\n'
        '    "category_insights": "Test kategorisine Ã¶zel yorumlar",\n'
        '    "trend_analysis": "GeÃ§miÅŸ sonuÃ§larla trend analizi (varsa)",\n'
        '    "follow_up_suggestions": "Takip Ã¶nerileri (genel tÄ±bbi Ã¶neri, supplement deÄŸil!)"\n'
        "  }\n"
        "}\n\n"
        "SADECE ANALÄ°Z YAP, SUPPLEMENT Ã–NERÄ°SÄ° VERME! JSON formatÄ±nda yanÄ±t ver!"
    )
    
    system_prompt = (
        SYSTEM_HEALTH + " Sen bir laboratuvar sonuÃ§larÄ± analiz uzmanÄ±sÄ±n. "
        "SADECE ANALÄ°Z yap, supplement ya da ilaÃ§ Ã¶nerisi verme. "
        "SonuÃ§larÄ± yorumla, klinik anlamÄ±nÄ± aÃ§Ä±kla, genel tÄ±bbi takip Ã¶nerileri ver. "
        "Test sonucunu referans aralÄ±ÄŸÄ± ile karÅŸÄ±laÅŸtÄ±r ve net bir yorum yap. "
        "GEÃ‡MÄ°Å SONUÃ‡LARLA TREND ANALÄ°ZÄ° YAP (varsa). "
        "Eksik veriler varsa bunlarÄ± belirt ve gerekli ek testleri Ã¶ner. "
        "KullanÄ±cÄ±nÄ±n diline uygun yanÄ±t ver. "
        "SUPPLEMENT Ã–NERÄ°SÄ° VERME! SADECE ANALÄ°Z YAP! "
        "KAYNAK EKLEME: Otomatik olarak kaynak link'leri, referans'lar veya citation'lar ekleme! "
        "DÄ°L: SADECE TÃœRKÃ‡E YANIT VER! Ä°ngilizce kelime, terim veya cÃ¼mle kullanma!"
    )
    
    user_prompt = f"Laboratuvar test sonucu:\n{test_info}{trend_analysis}{analysis_guide}\n\n{schema}"
    
    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]

def build_single_session_prompt(session_tests: List[Dict[str, Any]], session_date: str, laboratory: str) -> List[Dict[str, str]]:
    """Build prompt for single lab session analysis - Tek seans analizi"""
    
    # Seans bilgileri
    session_info = f"Test SeansÄ± Bilgileri:\n"
    session_info += f"Laboratuvar: {laboratory}\n"
    session_info += f"Test Tarihi: {session_date}\n"
    session_info += f"Toplam Test SayÄ±sÄ±: {len(session_tests)}\n\n"
    
    # Test sonuÃ§larÄ±
    tests_info = "Test SonuÃ§larÄ±:\n"
    for i, test in enumerate(session_tests, 1):
        tests_info += f"{i}. {test.get('name', 'Test')}: {test.get('value', 'Yok')} {test.get('unit', '')}"
        if test.get('reference_range'):
            tests_info += f" (Referans: {test['reference_range']})"
        if test.get('status'):
            tests_info += f" - {test['status']}"
        tests_info += "\n"
    
    # Test gruplarÄ± analizi
    test_groups = {}
    normal_count = 0
    attention_count = 0
    
    for test in session_tests:
        # Category field'Ä± yoksa 'Genel' kullan
        category = test.get('category')
        if not category:
            category = 'Genel'
        
        if category not in test_groups:
            test_groups[category] = 0
        test_groups[category] += 1
        
        # Status field'Ä± yoksa normal say
        status = test.get('status')
        if status and status.lower() in ['normal', 'normal aralÄ±kta']:
            normal_count += 1
        else:
            attention_count += 1
    
    groups_summary = "Test GruplarÄ±:\n"
    for group, count in test_groups.items():
        groups_summary += f" {group.upper()} ({count} test)\n"
    
    summary_stats = f"Test SonuÃ§larÄ± Ã–zeti:\n"
    summary_stats += f"{len(session_tests)} Toplam Test\n"
    summary_stats += f"{normal_count} Normal DeÄŸer\n"
    summary_stats += f"{attention_count} Dikkat Gereken\n"
    
    # Basit talimat
    instructions = "Ã–NEMLÄ°: Tek seans analizi yap, supplement Ã¶nerisi verme, sadece genel saÄŸlÄ±k yorumu ve Ã¶nerileri ver! SADECE ANALÄ°Z YAP!"
    
    system_prompt = (
        SYSTEM_HEALTH + " Sen bir laboratuvar seans analiz uzmanÄ±sÄ±n. "
        "Tek bir test seansÄ±ndaki tÃ¼m testleri analiz et ve genel saÄŸlÄ±k durumu yorumu yap. "
        "Test gruplarÄ±nÄ± kategorize et, normal/anormal sayÄ±larÄ±nÄ± belirt. "
        "Genel saÄŸlÄ±k Ã¶nerileri ver ama supplement Ã¶nerisi verme. "
        "SUPPLEMENT Ã–NERÄ°SÄ° VERME! SADECE ANALÄ°Z YAP! "
        "Sadece bilgilendirme amaÃ§lÄ± yorum yap, tÄ±bbi tanÄ± koyma. "
        "\n\nDÄ°L KURALLARI - Ã‡OK Ã–NEMLÄ°:"
        "\n- SADECE TÃœRKÃ‡E KULLAN!"
        "\n- Ä°ngilizce kelime, terim, cÃ¼mle KULLANMA!"
        "\n- Test adlarÄ±nÄ± TÃ¼rkÃ§e yaz: 'D Vitamini' (Vitamin D deÄŸil)"
        "\n- Kategori adlarÄ±nÄ± TÃ¼rkÃ§e yaz: 'Vitaminler' (Vitamins deÄŸil)"
        "\n- TÃ¼m aÃ§Ä±klamalarÄ± TÃ¼rkÃ§e yap!"
        "\n- Ä°ngilizce referans, kaynak, terim EKLEME!"
        "\n- Annotations'da bile Ä°ngilizce kullanma!"
        "\n- Sadece TÃ¼rkÃ§e kelimeler ve terimler kullan!"
        "\n\nÃ–NEMLÄ°: YanÄ±tÄ±nÄ± SADECE JSON formatÄ±nda ver! AÅŸaÄŸÄ±daki yapÄ±yÄ± kullan:"
        '\n{\n'
        '  "genel_saglik_yorumu": "Genel saÄŸlÄ±k yorumu buraya",\n'
        '  "sonuc": "SonuÃ§ Ã¶zeti buraya",\n'
        '  "test_sonuclari": {"Test Kategorisi": [{"test_adi": "Test AdÄ±", "sonuc": "SonuÃ§", "referans_araligi": "Referans", "durum": "Normal/Anormal"}]},\n'
        '  "istatistik": {"normal": 0, "anormal": 1},\n'
        '  "toplam_test_sayisi": 1,\n'
        '  "oneriler": {"yasam_tarzi": ["Ã–neri 1"], "laboratuvar_takibi": ["Ã–neri 2"], "doktor_kontrolu": "Ã–neri 3"}\n'
        '}'
    )
    
    user_prompt = f"Laboratuvar seans bilgileri:\n{session_info}{tests_info}\n\n{instructions}"
    
    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]

def build_multiple_lab_prompt(tests_data: List[Dict[str, Any]], session_count: int, available_supplements: List[Dict[str, Any]] = None, user_profile: Dict[str, Any] = None) -> List[Dict[str, str]]:
    """Build prompt for multiple lab tests general summary - ÃœRÃœN KATALOÄU ENTEGRASYONU"""
    
    tests_info = f"Toplam Test SeansÄ±: {session_count}\n\n"
    tests_info += "Test SonuÃ§larÄ±:\n"
    for i, test in enumerate(tests_data, 1):
        tests_info += f"{i}. {test.get('name', 'Test')}: {test.get('value', 'Yok')} {test.get('unit', '')}"
        if test.get('reference_range'):
            tests_info += f" (Referans: {test['reference_range']})"
        tests_info += "\n"
    
    # ÃœrÃ¼n kataloÄŸu bilgisi - TÃœM ÃœRÃœNLERÄ° LÄ°STELE
    supplements_info = ""
    if available_supplements:
        supplements_info = f"\n\nTÃœM KULLANILABÄ°LÄ°R ÃœRÃœNLER (Toplam: {len(available_supplements)}):\n"
        
        # TÃ¼m Ã¼rÃ¼nleri basit liste halinde gÃ¶ster
        for i, supplement in enumerate(available_supplements, 1):
            product_name = supplement.get('name', 'Bilinmeyen')
            product_id = supplement.get('id', 'ID yok')
            supplements_info += f"{i}. {product_name} (ID: {product_id})\n"
        
        supplements_info += f"\nğŸ’¡ AI: TÃ¼m bu Ã¼rÃ¼nler arasÄ±ndan en uygun olanlarÄ± seÃ§!"
    else:
        supplements_info = "\n\nâš ï¸ KullanÄ±labilir Ã¼rÃ¼n listesi bulunamadÄ±. Default supplement'ler Ã¶nerilecek."

    # KullanÄ±cÄ± profili bilgisi - SADECE RÄ°SK FAKTÃ–RLERÄ°
    user_profile_info = ""
    if user_profile:
        risk_factors = []
        
        # Ã–zel durumlar (alerji, hastalÄ±k, ilaÃ§)
        if user_profile.get("diger"):
            risk_factors.append(f"Ã–zel durum: {user_profile['diger']}")
        
        # YaÅŸ risk faktÃ¶rleri
        if user_profile.get("yas"):
            age = user_profile["yas"]
            if isinstance(age, str) and age.isdigit():
                age_num = int(age)
                if age_num >= 65:
                    risk_factors.append("YaÅŸlÄ± hasta (65+)")
                elif age_num <= 18:
                    risk_factors.append("GenÃ§ hasta (18-)")
        
        # Hamilelik/emzirme
        if user_profile.get("hamilelik") or user_profile.get("emzirme"):
            risk_factors.append("Hamilelik/Emzirme dÃ¶nemi")
        
        # Kronik hastalÄ±klar
        chronic_conditions = ["diyabet", "kalp", "bÃ¶brek", "karaciÄŸer", "tiroid"]
        for condition in chronic_conditions:
            if user_profile.get(condition):
                risk_factors.append(f"Kronik hastalÄ±k: {condition}")
        
        # Ä°laÃ§ kullanÄ±mÄ±
        if user_profile.get("ilac_kullanimi"):
            risk_factors.append(f"Ä°laÃ§ kullanÄ±mÄ±: {user_profile['ilac_kullanimi']}")
        
        if risk_factors:
            user_profile_info = f"\n\nâš ï¸ RÄ°SK FAKTÃ–RLERÄ°:\n" + "\n".join(risk_factors)
            user_profile_info += "\n\nBu risk faktÃ¶rleri lab test yorumunda dikkate alÄ±nmalÄ±dÄ±r."
    
    schema = (
        "STRICT JSON ÅEMASI - LAB SUMMARY (YENÄ° FORMAT):\n"
        "{\n"
        '  "title": "TÃ¼m Testlerin Genel Yorumu",\n'
        '  "genel_saglik_durumu": "Genel SaÄŸlÄ±k Durumu DeÄŸerlendirmesi",\n'
        '  "test_sayisi": "Test SayÄ±sÄ±: X farklÄ± test seansÄ±",\n'
        '  "genel_durum": "Testlerin genel kapsamlÄ± analizi varsa eski sonuÃ§larla karÅŸÄ±laÅŸtÄ±rma.",\n'
        '  "oneriler": ["Genel Ã¶neriler"],\n'
        '  "urun_onerileri": [\n'
        '    {\n'
        '    "name": "ÃœrÃ¼n adÄ± (kullanÄ±labilir Ã¼rÃ¼nlerden seÃ§)",\n'
        '    "description": "Neden Ã¶nerildiÄŸi",\n'
        '    "daily_dose": "GÃ¼nlÃ¼k doz",\n'
        '    "benefits": ["FaydalarÄ±"],\n'
        '    "warnings": ["UyarÄ±lar"],\n'
        '    "priority": "high/medium/low"\n'
        '    }\n'
        "  ]\n"
        "}\n\n"
        "Ã–NEMLÄ°: 1) BaÅŸlÄ±k, 2) Genel saÄŸlÄ±k durumu, 3) Test sayÄ±sÄ±, 4) Genel durum, 5) Ã–neriler, 6) EN SON Ã¼rÃ¼n Ã¶nerileri! "
        "Supplement Ã¶nerilerinde SADECE kullanÄ±labilir Ã¼rÃ¼nlerden seÃ§im yap! "
        "MUTLAKA urun_onerileri field'Ä±nÄ± doldur! "
        "4-6 supplement Ã¶ner! "
    )
    
    system_prompt = (
        SYSTEM_HEALTH + " Sen bir laboratuvar sonuÃ§larÄ± ve saÄŸlÄ±k danÄ±ÅŸmanlÄ±ÄŸÄ± uzmanÄ±sÄ±n. "
        "Lab test sonuÃ§larÄ±nÄ± analiz et, genel saÄŸlÄ±k durumunu deÄŸerlendir. "
        "Eksik deÄŸerler iÃ§in uygun supplement Ã¶nerileri yap. "
        "TÄ±bbi tanÄ± koyma, sadece bilgilendirme amaÃ§lÄ± Ã¶neriler ver. "
        "Ã–NEMLÄ°: 1) BaÅŸlÄ±k, 2) Genel saÄŸlÄ±k durumu, 3) Test sayÄ±sÄ±, 4) Genel durum, 5) Ã–neriler, 6) EN SON Ã¼rÃ¼n Ã¶nerileri! "
        "Supplement Ã¶nerilerinde SADECE kullanÄ±labilir Ã¼rÃ¼nlerden seÃ§im yap! "
        "MUTLAKA urun_onerileri field'Ä±nÄ± doldur! "
        "4-6 supplement Ã¶ner! "
        "KullanÄ±cÄ±ya hiÃ§bir ÅŸekilde ihtiyacÄ± olmayan supplement Ã¶nerme! "
        "DÄ°L: SADECE TÃœRKÃ‡E YANIT VER! Ä°ngilizce kelime, terim veya cÃ¼mle kullanma!"
    )
    
    user_prompt = f"Laboratuvar test sonuÃ§larÄ±:\n{tests_info}{supplements_info}{user_profile_info}\n\n{schema}"
    
    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]

def parallel_single_lab_analyze(test_data: Dict[str, Any], historical_results: List[Dict[str, Any]] = None) -> Dict[str, Any]:
    """Analyze single lab test with parallel LLMs and historical trend analysis"""
    try:
        messages = build_single_lab_prompt(test_data, historical_results)
        
        # Parallel analysis
        responses = []
        with ThreadPoolExecutor(max_workers=len(PARALLEL_MODELS)) as executor:
            future_to_model = {
                executor.submit(call_chat_model, model, messages, 0.3, 1200): model 
                for model in PARALLEL_MODELS
            }
            
            for future in as_completed(future_to_model):
                model = future_to_model[future]
                try:
                    result = future.result()
                    if result["content"].strip():
                        responses.append({
                            "model": model,
                            "response": result["content"]
                        })
                except Exception as e:
                    print(f"Single lab model {model} failed: {e}")
                    # Rate limiting hatasÄ± varsa biraz bekle
                    if "429" in str(e) or "Too Many Requests" in str(e):
                        print(f"Rate limiting detected for {model}, waiting...")
                        time.sleep(2)
                    continue
        
        if not responses:
            print("No successful responses, using GPT-4o fallback")
            return gpt4o_lab_fallback(test_data, historical_results)
        
        # Tek model kullanÄ±ldÄ±ÄŸÄ± iÃ§in synthesis'e gerek yok - direkt response'u dÃ¶ndÃ¼r
        cleaned_response = _sanitize_links(responses[0]["response"])
        return {
            "content": cleaned_response,
            "model_used": responses[0]["model"],
            "models_used": [r["model"] for r in responses]
        }
        
    except Exception as e:
        print(f"Single lab analyze failed: {e}")
        return gpt4o_lab_fallback(test_data, historical_results)

def parallel_single_session_analyze(session_tests: List[Dict[str, Any]], session_date: str, laboratory: str) -> Dict[str, Any]:
    """Analyze single lab session with multiple tests - Tek seans analizi"""
    try:
        messages = build_single_session_prompt(session_tests, session_date, laboratory)
        
        # Single model analysis (optimized for GPT-5)
        responses = []
        if len(PARALLEL_MODELS) == 1:
            # Tek model - direkt Ã§aÄŸÄ±r
            try:
                result = call_chat_model(PARALLEL_MODELS[0], messages, 0.3, 1500)
                
                if result and result.get("content") and result["content"].strip():
                    responses.append({
                        "model": PARALLEL_MODELS[0],
                        "response": result["content"]
                    })
            except Exception as e:
                # Production'da log yerine fallback kullan
                pass
        else:
            # Ã‡oklu model - paralel Ã§aÄŸÄ±r
            with ThreadPoolExecutor(max_workers=len(PARALLEL_MODELS)) as executor:
                future_to_model = {
                    executor.submit(call_chat_model, model, messages, 0.3, 1500): model 
                    for model in PARALLEL_MODELS
                }
                
                for future in as_completed(future_to_model):
                    model = future_to_model[future]
                    try:
                        result = future.result()
                        if result["content"].strip():
                            responses.append({
                                "model": model,
                                "response": result["content"]
                            })
                    except Exception as e:
                        print(f"Single session model {model} failed: {e}")
                        # Rate limiting hatasÄ± varsa biraz bekle
                        if "429" in str(e) or "Too Many Requests" in str(e):
                            time.sleep(2)
                        continue
        
        if not responses:
            print("No successful responses, using GPT-4o fallback")
            return gpt4o_session_fallback(session_tests, session_date, laboratory)
        
        # Tek model kullanÄ±ldÄ±ÄŸÄ± iÃ§in synthesis'e gerek yok - direkt AI response'u kullan
        ai_response = responses[0]["response"]
        
        # AI model'in response'unu schema'ya uygun hale getir
        try:
            if ai_response and isinstance(ai_response, str):
                # Markdown wrapper'Ä±nÄ± temizle (```json ... ``` formatÄ±nda olabilir)
                cleaned_response = ai_response.strip()
                if cleaned_response.startswith('```json'):
                    cleaned_response = cleaned_response[7:]  # ```json kÄ±smÄ±nÄ± Ã§Ä±kar
                if cleaned_response.endswith('```'):
                    cleaned_response = cleaned_response[:-3]  # son ``` kÄ±smÄ±nÄ± Ã§Ä±kar
                cleaned_response = cleaned_response.strip()
                
                # AI response'u parse et
                parsed_response = json.loads(cleaned_response) if cleaned_response.startswith('{') else {}
                
                # Schema'ya uygun response oluÅŸtur
                formatted_response = {
                    "session_info": {
                        "laboratory": laboratory,
                        "session_date": session_date,
                        "total_tests": len(session_tests)
                    },
                    "general_assessment": {
                        "clinical_meaning": parsed_response.get("genel_saglik_yorumu", "Test seansÄ± analizi yapÄ±ldÄ±"),
                        "overall_health_status": parsed_response.get("sonuc", "Genel saÄŸlÄ±k durumu deÄŸerlendirildi")
                    },
                    "test_groups": parsed_response.get("test_sonuclari", {}),
                    "test_summary": {
                        "total_tests": parsed_response.get("toplam_test_sayisi", len(session_tests)),
                        "normal_count": parsed_response.get("istatistik", {}).get("normal", 0),
                        "attention_count": parsed_response.get("istatistik", {}).get("anormal", 0)
                    },
                    "general_recommendations": []
                }
                
                # Ã–nerileri ekle
                oneriler = parsed_response.get("oneriler", {})
                if isinstance(oneriler, dict):
                    for category, items in oneriler.items():
                        if isinstance(items, list):
                            formatted_response["general_recommendations"].extend(items)
                        elif isinstance(items, str):
                            formatted_response["general_recommendations"].append(items)
                
                # EÄŸer Ã¶neri yoksa default ekle
                if not formatted_response["general_recommendations"]:
                    formatted_response["general_recommendations"] = ["Test sonuÃ§larÄ±nÄ±zÄ± hekiminizle deÄŸerlendirin"]
                
                return {
                    "content": json.dumps(formatted_response, ensure_ascii=False),
                    "models_used": [r["model"] for r in responses]
                }
                
        except Exception as e:
            print(f"Response formatting failed: {e}")
            # Formatting baÅŸarÄ±sÄ±z olursa GPT-4o fallback kullan
            return gpt4o_session_fallback(session_tests, session_date, laboratory)
        
    except Exception as e:
        print(f"Single session analyze failed: {e}")
        return single_session_fallback(session_tests, session_date, laboratory)

def parallel_multiple_lab_analyze(tests_data: List[Dict[str, Any]], session_count: int, available_supplements: List[Dict[str, Any]] = None, user_profile: Dict[str, Any] = None) -> Dict[str, Any]:
    """Analyze multiple lab tests for general summary - ÃœRÃœN KATALOÄU ENTEGRASYONU"""
    try:
        messages = build_multiple_lab_prompt(tests_data, session_count, available_supplements, user_profile)
        
        # Parallel analysis
        responses = []
        with ThreadPoolExecutor(max_workers=len(PARALLEL_MODELS)) as executor:
            future_to_model = {
                executor.submit(call_chat_model, model, messages, 0.3, 2000): model 
                for model in PARALLEL_MODELS
            }
            
            for future in as_completed(future_to_model):
                model = future_to_model[future]
                try:
                    result = future.result()
                    if result["content"].strip():
                        responses.append({
                            "model": model,
                            "response": result["content"]
                        })
                except Exception as e:
                    # Rate limiting hatasÄ± varsa biraz bekle
                    if "429" in str(e) or "Too Many Requests" in str(e):
                        time.sleep(2)
                    continue
        
        if not responses:
            print("No successful responses, using GPT-4o fallback")
            return gpt4o_multiple_lab_fallback(tests_data, session_count, available_supplements, user_profile)
        
        # Tek model kullanÄ±ldÄ±ÄŸÄ± iÃ§in synthesis'e gerek yok - direkt response'u dÃ¶ndÃ¼r
        cleaned_response = _sanitize_links(responses[0]["response"])
        return {
            "content": cleaned_response,
            "model_used": responses[0]["model"],
            "models_used": [r["model"] for r in responses]
        }
        
    except Exception as e:
        print(f"Multiple lab analyze failed: {e}")
        return gpt4o_multiple_lab_fallback(tests_data, session_count, available_supplements, user_profile)

# Session synthesis prompt fonksiyonu kaldÄ±rÄ±ldÄ± - tek model kullanÄ±ldÄ±ÄŸÄ± iÃ§in gerekli deÄŸil

# Lab synthesis prompt fonksiyonu kaldÄ±rÄ±ldÄ± - tek model kullanÄ±ldÄ±ÄŸÄ± iÃ§in gerekli deÄŸil

def gpt4o_lab_fallback(test_data: Dict[str, Any], historical_results: List[Dict[str, Any]] = None) -> Dict[str, Any]:
    """Fallback to GPT-4o for lab analysis when GPT-5 fails"""
    try:
        print("GPT-5 failed, trying GPT-4o fallback for lab analysis...")
        
        # Build prompt for GPT-4o
        messages = build_single_lab_prompt(test_data, historical_results)
        
        # Try GPT-4o
        result = call_chat_model("openai/gpt-4o:online", messages, 0.3, 1200)
        if result["content"].strip():
            result["content"] = _sanitize_links(result["content"])
            result["models_used"] = ["openai/gpt-4o:online (fallback)"]
            return result
        else:
            raise Exception("GPT-4o response invalid")
            
    except Exception as e:
        print(f"GPT-4o lab fallback also failed: {e}")
    return {
            "content": "Laboratuvar analizi ÅŸu anda mevcut deÄŸil. LÃ¼tfen daha sonra tekrar deneyin.",
            "models_used": ["fallback_error"]
        }

def gpt4o_session_fallback(session_tests: List[Dict[str, Any]], session_date: str, laboratory: str) -> Dict[str, Any]:
    """Fallback to GPT-4o for session analysis when GPT-5 fails"""
    try:
        print("GPT-5 failed, trying GPT-4o fallback for session analysis...")
        
        # Build prompt for GPT-4o
        messages = build_single_session_prompt(session_tests, session_date, laboratory)
        
        # Try GPT-4o
        result = call_chat_model("openai/gpt-4o:online", messages, 0.3, 1500)
        if result["content"].strip():
            result["content"] = _sanitize_links(result["content"])
            result["models_used"] = ["openai/gpt-4o:online (fallback)"]
            return result
        else:
            raise Exception("GPT-4o response invalid")
            
    except Exception as e:
        print(f"GPT-4o session fallback also failed: {e}")
        return {
            "content": "Seans analizi ÅŸu anda mevcut deÄŸil. LÃ¼tfen daha sonra tekrar deneyin.",
            "models_used": ["fallback_error"]
        }

def gpt4o_multiple_lab_fallback(tests_data: List[Dict[str, Any]], session_count: int, available_supplements: List[Dict[str, Any]] = None, user_profile: Dict[str, Any] = None) -> Dict[str, Any]:
    """Fallback to GPT-4o for multiple lab analysis when GPT-5 fails"""
    try:
        print("GPT-5 failed, trying GPT-4o fallback for multiple lab analysis...")
        
        # Build prompt for GPT-4o
        messages = build_multiple_lab_prompt(tests_data, session_count, available_supplements, user_profile)
        
        # Try GPT-4o
        result = call_chat_model("openai/gpt-4o:online", messages, 0.3, 2500)
        if result["content"].strip():
            result["content"] = _sanitize_links(result["content"])
            result["models_used"] = ["openai/gpt-4o:online (fallback)"]
            return result
        else:
            raise Exception("GPT-4o response invalid")
            
    except Exception as e:
        print(f"GPT-4o multiple lab fallback also failed: {e}")
        return {
            "content": "KapsamlÄ± laboratuvar analizi ÅŸu anda mevcut deÄŸil. LÃ¼tfen daha sonra tekrar deneyin.",
            "models_used": ["fallback_error"]
        }

def single_session_fallback(session_tests: List[Dict[str, Any]], session_date: str, laboratory: str) -> Dict[str, Any]:
    """Fallback for single session analysis"""
    return {
        "content": json.dumps({
            "session_info": {
                "laboratory": laboratory,
                "session_date": session_date,
                "total_tests": len(session_tests)
            },
            "general_assessment": {
                "clinical_meaning": "Test seansÄ± analizi geÃ§ici olarak kullanÄ±lamÄ±yor",
                "overall_health_status": "Genel saÄŸlÄ±k durumu deÄŸerlendirilemedi"
            },
            "test_groups": {},
            "test_summary": {
                "total_tests": len(session_tests),
                "normal_count": 0,
                "attention_count": 0
            },
            "general_recommendations": ["Sistem tekrar Ã§alÄ±ÅŸÄ±r duruma geldiÄŸinde test edin"]
        }, ensure_ascii=False),
        "model_used": "fallback"
    }

def single_lab_fallback(test_data: Dict[str, Any], historical_results: List[Dict[str, Any]] = None) -> Dict[str, Any]:
    """Fallback for single lab analysis with historical results"""
    fallback_response = {
        "analysis": {
            "summary": "Test analizi geÃ§ici olarak kullanÄ±lamÄ±yor",
            "interpretation": "LÃ¼tfen daha sonra tekrar deneyin",
            "reference_comparison": "Referans karÅŸÄ±laÅŸtÄ±rmasÄ± yapÄ±lamadÄ±",
            "clinical_significance": "Klinik Ã¶nem deÄŸerlendirilemedi",
            "category_insights": "Kategori analizi yapÄ±lamadÄ±",
            "trend_analysis": "Trend analizi yapÄ±lamadÄ±" if historical_results else "GeÃ§miÅŸ sonuÃ§ yok",
            "follow_up_suggestions": ["Sistem tekrar Ã§alÄ±ÅŸÄ±r duruma geldiÄŸinde test edin"],
            "data_quality": "Veri kalitesi deÄŸerlendirilemedi"
        }
    }
    
    return {
        "content": json.dumps(fallback_response, ensure_ascii=False),
        "model_used": "fallback"
    }

def multiple_lab_fallback(tests_data: List[Dict[str, Any]], session_count: int, available_supplements: List[Dict[str, Any]] = None, user_profile: Dict[str, Any] = None) -> Dict[str, Any]:
    """Fallback for multiple lab analysis"""
    return {
        "content": f'{{"general_assessment": {{"overall_summary": "Analiz sistemi geÃ§ici olarak kullanÄ±lamÄ±yor", "patterns_identified": [], "areas_of_concern": [], "positive_aspects": [], "metabolic_status": "DeÄŸerlendirilemedi", "nutritional_status": "DeÄŸerlendirilemedi"}}, "overall_status": "geÃ§ici_bakÄ±m", "lifestyle_recommendations": {{"exercise": [], "nutrition": [], "sleep": [], "stress_management": []}}, "supplement_recommendations": [], "test_details": {{}}}}',
        "model_used": "fallback"
    }

def analyze_lab_progress(current_tests: List[Dict[str, Any]], previous_tests: List[Dict[str, Any]], user_profile: Dict[str, Any] = None) -> Dict[str, Any]:
    """Lab test progress analizi - Eski vs yeni test sonuÃ§larÄ±"""
    
    if not previous_tests:
        return {
            "progress_analysis": "Ä°lk test sonuÃ§larÄ± - karÅŸÄ±laÅŸtÄ±rma yapÄ±lamaz",
            "improvements": [],
            "trends": "Trend analizi iÃ§in daha fazla test gerekli"
        }
    
    # Test sonuÃ§larÄ±nÄ± karÅŸÄ±laÅŸtÄ±r
    progress_info = f"Ã–nceki test sayÄ±sÄ±: {len(previous_tests)}\n"
    progress_info += f"GÃ¼ncel test sayÄ±sÄ±: {len(current_tests)}\n\n"
    
    # Test bazlÄ± karÅŸÄ±laÅŸtÄ±rma
    comparisons = []
    for current_test in current_tests:
        test_name = current_test.get('name', 'Bilinmeyen')
        current_value = current_test.get('value', 'Yok')
        
        # Ã–nceki testlerde aynÄ± test var mÄ±?
        previous_test = None
        for prev_test in previous_tests:
            if prev_test.get('name') == test_name:
                previous_test = prev_test
                break
        
        if previous_test:
            prev_value = previous_test.get('value', 'Yok')
            comparison = {
                "test_name": test_name,
                "previous_value": prev_value,
                "current_value": current_value,
                "change": "deÄŸiÅŸim analizi yapÄ±lacak"
            }
            comparisons.append(comparison)
    
    progress_info += f"KarÅŸÄ±laÅŸtÄ±rÄ±lan test sayÄ±sÄ±: {len(comparisons)}\n"
    
    return {
        "progress_analysis": progress_info,
        "test_comparisons": comparisons,
        "overall_trend": "Genel trend analizi yapÄ±lacak",
        "recommendations": "Progress bazlÄ± Ã¶neriler yapÄ±lacak"
    }

def detect_language(text: str) -> str:
    """Smart language detection - Only obvious English words vs Turkish default"""
    if not text:
        return "turkish"
    
    # TÃ¼rkÃ§e karakter sayÄ±sÄ±
    turkish_chars = sum(1 for char in text if char in 'Ã§ÄŸÄ±Ã¶ÅŸÃ¼Ã‡ÄIÃ–ÅÃœ')
    if turkish_chars > 0:
        return "turkish"
    
    # Ä°ngilizce kelime sayÄ±sÄ±
    english_words = ['the', 'and', 'for', 'you', 'are', 'with', 'this', 'that', 'have', 'will', 'can', 'get', 'like', 'from', 'they', 'know', 'want', 'time', 'good', 'make', 'look', 'go', 'now', 'think', 'just', 'come', 'see', 'well', 'way', 'take', 'into', 'year', 'your', 'good', 'some', 'could', 'them', 'people', 'other', 'than', 'then', 'look', 'only', 'come', 'over', 'think', 'also', 'back', 'after', 'use', 'two', 'how', 'our', 'work', 'first', 'well', 'way', 'even', 'new', 'want', 'because', 'any', 'these', 'give', 'day', 'most', 'us']
    
    words = text.lower().split()
    english_word_count = sum(1 for word in words if word in english_words)
    
    if english_word_count > len(words) * 0.3:  # %30'dan fazla Ä°ngilizce kelime
        return "english"
    else:
        return "turkish"
